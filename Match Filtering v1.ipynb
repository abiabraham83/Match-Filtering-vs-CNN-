{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7255370-36f9-434a-a01f-78d2298cc235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/ian.harry/tmp_abi': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! ls /home/ian.harry/tmp_abi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524a0818-a741-4077-beee-ce7c7110d41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/ian.harry/tmp_abi/template_bank': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ian.harry/tmp_abi/template_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7657aa22-c3e4-4df0-8d18-548fcd8b940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as py\n",
    "import pandas as pd \n",
    "import pycbc\n",
    "import glob, os\n",
    "import h5py\n",
    "import lal \n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "#pycbc specifically for gravitational wave astronomy. For more information on github, follow this link: https://github.com/gwastro/pycbc\n",
    "import pycbc.noise\n",
    "import pycbc.filter\n",
    "import pycbc.psd\n",
    "from pycbc.filter import highpass_fir, matched_filter, matched_filter_core, MatchedFilterControl, sigmasq\n",
    "from pycbc.filter.matchedfilter import Correlator\n",
    "from pycbc.types import zeros\n",
    "from pycbc.fft import IFFT\n",
    "from pycbc.waveform import get_td_waveform, get_fd_waveform\n",
    "from pycbc.waveform import td_approximants, fd_approximants\n",
    "\n",
    "from scipy.signal import tukey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f35ef80-03f8-405b-a109-a916d93226eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465307a-4de2-480d-8c21-ad0e625c7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Csv file of data ids and their coresponding targets. \n",
    "training_labels = pd.read_csv(\"/home/ian.harry/tmp_abi/training_labels.csv\")\n",
    "training_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221641f-0d15-47ce-a100-b61f76a0c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary containing ids and targets\n",
    "tl = np.loadtxt('/home/ian.harry/tmp_abi/training_labels.csv',dtype='str', delimiter=',',skiprows=1)\n",
    "\n",
    "dict_tl={}\n",
    "\n",
    "for i in tl:\n",
    "    dict_tl[i[0]] = i[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46941baf-28da-43ab-b2e6-427e54988eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tl['0000c3b9c9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f60ab-67dc-4053-bfa2-c12e64b77fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = list(dict_tl)\n",
    "a_key = keys_list[13]\n",
    "print(a_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c0384-e730-460b-b337-0c8f411b4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keys_list[:10])\n",
    "keys_list.index('0000c3b9c9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61fcf95-7f59-4f52-985e-7d4293e2561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_l = training_labels[:155]\n",
    "tl_0 = t_l.loc[t_l['target'] == 0]\n",
    "print(len(tl_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8213b05e-cfd5-4d55-8a69-b96cd81d47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ffcfc-8cac-483c-9961-1c9fa4cb9726",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258667ac-6479-4d85-8289-26d4f6304126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the PSD, code inspired from  my supervisor Ian Harry.\n",
    "data_in = glob.glob('/home/ian.harry/tmp_abi/train/0/0/0/*.npy')\n",
    "\n",
    "det1_psd = None \n",
    "det2_psd = None \n",
    "det3_psd = None \n",
    "count = 0\n",
    "\n",
    "for filename in data_in:\n",
    "    file_id = filename.split(\"/\")[8].split('.')[0]\n",
    "    \n",
    "    if dict_tl[file_id] == 1:\n",
    "        continue\n",
    "    count += 1\n",
    "    \n",
    "    example_arr = np.load(filename)\n",
    "    det1 = pycbc.types.TimeSeries(example_arr[0], delta_t= 1./2048.)#Splits the file path to just the id name\n",
    "    det2 = pycbc.types.TimeSeries(example_arr[1], delta_t= 1./2048.) \n",
    "    det3 = pycbc.types.TimeSeries(example_arr[2], delta_t= 1./2048.)\n",
    "    window = np.hanning(4096) \n",
    "    \n",
    "    det1 = det1*window #applies window to minimise wrap arouind effect.\n",
    "    det2 = det2*window\n",
    "    det3 = det3*window \n",
    "    \n",
    "    det1f = det1.to_frequencyseries() #Transform into the frequency domain\n",
    "    det2f = det2.to_frequencyseries()\n",
    "    det3f = det3.to_frequencyseries()\n",
    "    \n",
    "    if count == 1:\n",
    "        det1_psd = abs(det1f)\n",
    "        det2_psd = abs(det2f)\n",
    "        det3_psd = abs(det3f)\n",
    "    else:\n",
    "        det1_psd = (abs(det1f) + (count-1) * det1_psd)/count\n",
    "        det2_psd = (abs(det2f) + (count-1) * det2_psd)/count \n",
    "        det3_psd = (abs(det3f) + (count-1) * det3_psd)/count\n",
    "        \n",
    "det1_psd = det1_psd**2 * 4096/ (window*window).sum() # computes the average PSD\n",
    "det2_psd = det2_psd**2 * 4096/ (window*window).sum()\n",
    "det3_psd = det3_psd**2 * 4096/ (window*window).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682120f-7e41-4c57-b0d6-bfbf1fe84f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "py.figure(figsize=(8,8))\n",
    "py.loglog(det1_psd.sample_frequencies, det1_psd, label='Detector 1')\n",
    "py.loglog(det2_psd.sample_frequencies, det2_psd, label='Detector 2')\n",
    "py.loglog(det3_psd.sample_frequencies, det3_psd,label='Detector 3')\n",
    "py.legend()\n",
    "py.xlim(100,1100)\n",
    "py.ylim(10e-50,10e-45)\n",
    "py.xlabel('Frequency (Hz)')\n",
    "py.ylabel('Strain')\n",
    "PSD_match = plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac401bb-f1da-494c-ac92-4d104d1eef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSD_match.savefig('PSD_match.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40794371-1dd5-404d-8ff1-32b9836ba58b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating Waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3647663-957a-43c8-84a4-5ed235aeb41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Template bank provided by Ian Harry - contains 3000 waveforms\n",
    "templates = h5py.File('/home/ian.harry/tmp_abi/template_bank/templates_097.h5', mode= 'r')\n",
    "mass1s = (templates['mass1'][:1])\n",
    "mass2s = (templates['mass2'][:1])\n",
    "spin1z = (templates['spin1z'][:1])\n",
    "spin2z = (templates['spin2z'][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6686b3-8946-457f-834f-3e89897691be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute the lower frequency for the set of masses\n",
    "def f_lower(M_chirp):\n",
    "    return (5**(3/8))/(8*np.pi*((M_chirp**(5/3)*1)**(3/8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ec0ad-f91d-48a3-a1ec-06e9a42ddec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#py.figure(figsize=(10,10))\n",
    "for m1, m2, s1z, s2z in zip(mass1s,mass2s,spin1z,spin2z):\n",
    "    mu = ((m1*m2)/(m1+m2))\n",
    "    M = m1+m2\n",
    "    M_chirp = (mu**(3/5))*(M**(2/5))*lal.MTSUN_SI # computing the chirp mass\n",
    "    hp,hc = get_fd_waveform(approximant='IMRPhenomD',\n",
    "                                                      mass1 = m1,\n",
    "                                                      mass2 = m2, \n",
    "                                                      spin1z = s1z,\n",
    "                                                      spin2z = s2z,\n",
    "                                                      delta_f=det1_psd.delta_f, # frequency step\n",
    "                                                      f_lower=f_lower(M_chirp),\n",
    "                                                      f_upper=1024)\n",
    "    hp.resize(len(det1_fs))\n",
    "    #py.plot(hp.sample_frequencies,h )\n",
    "print(hp.delta_f,len(hp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23752de-af3e-4cf0-b142-19d30c0641e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(det1f.delta_f,hp.delta_f,det1_psd.delta_f)\n",
    "hp.resize(len(det1f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cab4f2-9c84-425c-9205-7642af8b9a96",
   "metadata": {},
   "source": [
    "## Match Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9c5dd-18ae-424d-965b-a3b519c55a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning ids to a path\n",
    "training_labels = pd.read_csv(\"/home/ian.harry/tmp_abi/training_labels.csv\")\n",
    "\n",
    "path = list(training_labels['id'])\n",
    "for i in range(len(path)):\n",
    "    path[i] = '/home/ian.harry/tmp_abi/train/' + path[i][0] +  '/' + path[i][1] +  '/' + path[i][2] +  '/' + path[i] + '.npy'\n",
    "print(path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f72e1-8c2f-4840-827c-8c8c02a12156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(path)//50 # reducing the data size\n",
    "print(data_size)\n",
    "data_in = path[0:data_size]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e113ba2-b646-4c0c-92ff-c5731a0e6231",
   "metadata": {},
   "source": [
    "# My original code, without proper optimisation, it is quite slow though.\n",
    "det_filter_final = []\n",
    "\n",
    "\n",
    "for filname in data_in:\n",
    "    \n",
    "    ex_arr = np.load(filname)\n",
    "    window = tukey(4096, alpha=0.1)\n",
    "\n",
    "    det1_ts = pycbc.types.TimeSeries(ex_arr[0], delta_t= 1./2048.)\n",
    "    det1_ts = det1_ts * window # I think you need a window here!\n",
    "    det2_ts = pycbc.types.TimeSeries(ex_arr[1], delta_t= 1./2048.) \n",
    "    det2_ts = det2_ts * window # I think you need a window here!\n",
    "    det3_ts = pycbc.types.TimeSeries(ex_arr[2], delta_t= 1./2048.)\n",
    "    det3_ts = det3_ts * window # I think you need a window here!\n",
    "\n",
    "    det1_fs = det1_ts.to_frequencyseries()\n",
    "    det2_fs = det2_ts.to_frequencyseries()\n",
    "    det3_fs = det3_ts.to_frequencyseries()\n",
    "\n",
    "    max_icv = 0\n",
    "    for m1, m2, s1z, s2z in zip(mass1s,mass2s,spin1z,spin2z):\n",
    "        mu = ((m1*m2)/(m1+m2))\n",
    "        M = m1+m2\n",
    "        M_chirp = (mu**(3/5))*(M**(2/5))*lal.MTSUN_SI\n",
    "        hp,hc = get_fd_waveform(approximant='IMRPhenomD',\n",
    "                                                          mass1 = m1,\n",
    "                                                          mass2 = m2, \n",
    "                                                          spin1z = s1z,\n",
    "                                                          spin2z = s2z,\n",
    "                                                          delta_f= det1_psd.delta_f,\n",
    "                                                          f_lower=30,\n",
    "                                                          f_upper=1000)\n",
    "        hp.resize(len(det1_fs))\n",
    "        det1_filter = matched_filter(hp,det1_fs,psd=det1_psd, low_frequency_cutoff=20, high_frequency_cutoff=1000)\n",
    "        det2_filter = matched_filter(hp,det2_fs,psd=det2_psd, low_frequency_cutoff=20, high_frequency_cutoff=1000)\n",
    "        det3_filter = matched_filter(hp,det3_fs,psd=det3_psd, low_frequency_cutoff=20, high_frequency_cutoff=1000)\n",
    "        \n",
    "        det1_filter = det1_filter[3030:3745]\n",
    "        det2_filter = det2_filter[3030:3745]\n",
    "        det3_filter = det3_filter[3030:3745]\n",
    "        \n",
    "        max_det1_filter = abs(det1_filter).numpy().argmax()\n",
    "        det1_max = abs(det1_filter[max_det1_filter])\n",
    "    \n",
    "        max_det2_filter = abs(det2_filter).numpy().argmax()\n",
    "        det2_max = abs(det2_filter[max_det2_filter])\n",
    "  \n",
    "        max_det3_filter = abs(det3_filter).numpy().argmax()\n",
    "        det3_max = abs(det3_filter[max_det3_filter])\n",
    "        \n",
    "        max_filter = (det1_max+det2_max+det3_max)\n",
    "        \n",
    "        if max_filter > max_icv:\n",
    "            max_icv = max_filter                \n",
    "    \n",
    "    det_filter_final.append(max_icv)\n",
    "    \n",
    "print(len(det_filter_final))   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d9aa13-d666-4545-b901-cf33f7e28ecb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Same principle as my code but optimized by Ian Harry\n",
    "\n",
    "det_filter_final = []\n",
    "from pycbc.filter.matchedfilter import _BaseCorrelator\n",
    "\n",
    "class CPUCorrelator(_BaseCorrelator):\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = np.array(x.data, copy=False)\n",
    "        self.y = np.array(y.data, copy=False)\n",
    "        self.z = np.array(z.data, copy=False)\n",
    "\n",
    "    def correlate(self):\n",
    "        self.z[:] = np.conjugate(self.x.data)\n",
    "        self.z *= self.y\n",
    "\n",
    "print(\"Pregenerating waveforms and normalizations\")\n",
    "pregenerated_waveforms = []\n",
    "pregenerated_sigma1s = []\n",
    "pregenerated_sigma2s = []\n",
    "pregenerated_sigma3s = []\n",
    "\n",
    "for m1, m2, s1z, s2z in zip(mass1s,mass2s,spin1z,spin2z):\n",
    "        mu = ((m1*m2)/(m1+m2))\n",
    "        M = m1+m2\n",
    "        M_chirp = (mu**(3/5))*(M**(2/5))*lal.MTSUN_SI\n",
    "        hp,hc = get_fd_waveform(approximant='IMRPhenomD',\n",
    "                                                          mass1 = m1,\n",
    "                                                          mass2 = m2, \n",
    "                                                          spin1z = s1z,\n",
    "                                                          spin2z = s2z,\n",
    "                                                          delta_f= det1_psd.delta_f,\n",
    "                                                          f_lower=f_lower(M_chirp),\n",
    "                                                          f_upper=1000)\n",
    "        hp.resize(len(det1_psd))\n",
    "        pregenerated_waveforms.append(hp)\n",
    "        # sigma squared is a normalisation constant to compute the correct SNR.\n",
    "        template_norm1 = sigmasq(hp, det1_psd, low_frequency_cutoff=30, high_frequency_cutoff=1000)\n",
    "        template_norm2 = sigmasq(hp, det2_psd, low_frequency_cutoff=30, high_frequency_cutoff=1000)\n",
    "        template_norm3 = sigmasq(hp, det3_psd, low_frequency_cutoff=30, high_frequency_cutoff=1000)\n",
    "        pregenerated_sigma1s.append(template_norm1)\n",
    "        pregenerated_sigma2s.append(template_norm2)\n",
    "        pregenerated_sigma3s.append(template_norm3)\n",
    "\n",
    "print(\"Beginning to process data\")\n",
    "\n",
    "    \n",
    "det_filter_final = []\n",
    "for filname in data_in:\n",
    "    \n",
    "    ##### GET DATA\n",
    "    ex_arr = np.load(filname)\n",
    "    print(filname, filname.split('/')[-1][:-4], dict_tl[filname.split('/')[-1][:-4]])\n",
    "\n",
    "    ex_arr = np.load(filname)\n",
    "    window = tukey(4096, alpha=0.05)\n",
    "\n",
    "    det1_ts = pycbc.types.TimeSeries(ex_arr[0], delta_t= 1./2048.)\n",
    "    det1_ts = det1_ts * window # I think you need a window here!\n",
    "    det2_ts = pycbc.types.TimeSeries(ex_arr[1], delta_t= 1./2048.) \n",
    "    det2_ts = det2_ts * window # I think you need a window here!\n",
    "    det3_ts = pycbc.types.TimeSeries(ex_arr[2], delta_t= 1./2048.)\n",
    "    det3_ts = det3_ts * window # I think you need a window here!\n",
    "\n",
    "\n",
    "    det1_fs = det1_ts.to_frequencyseries()\n",
    "    det2_fs = det2_ts.to_frequencyseries()\n",
    "    det3_fs = det3_ts.to_frequencyseries()\n",
    "    \n",
    "    # Apply PSD here\n",
    "    det1_fs = det1_fs / det1_psd\n",
    "    det2_fs = det2_fs / det2_psd\n",
    "    det3_fs = det3_fs / det3_psd\n",
    "    \n",
    "    ##### SET UP CORRELATORS AND FFTs\n",
    "\n",
    "    tlen = 2 * 2048 # Length of data is 4096 data points\n",
    "    flen = tlen // 2 + 1\n",
    "    data_time_length = 2\n",
    "    template_mem1 = zeros(tlen, dtype = np.complex128)\n",
    "    template_mem2 = zeros(tlen, dtype = np.complex128)\n",
    "    template_mem3 = zeros(tlen, dtype = np.complex128)\n",
    "    snr_mem1 = zeros(tlen, dtype=np.complex128)\n",
    "    snr_mem2 = zeros(tlen, dtype=np.complex128)\n",
    "    snr_mem3 = zeros(tlen, dtype=np.complex128)\n",
    "    corr_mem1 = zeros(tlen, dtype=np.complex128)\n",
    "    corr_mem2 = zeros(tlen, dtype=np.complex128)\n",
    "    corr_mem3 = zeros(tlen, dtype=np.complex128)\n",
    "    # Low and high frequency cutoffs\n",
    "    kmin = 30 * data_time_length\n",
    "    kmax = 1000 * data_time_length\n",
    "    corr_slice = slice(kmin, kmax)\n",
    "    corr1 = CPUCorrelator(template_mem1[corr_slice], det1_fs[corr_slice], corr_mem1[corr_slice])\n",
    "    corr2 = CPUCorrelator(template_mem2[corr_slice], det2_fs[corr_slice], corr_mem2[corr_slice])\n",
    "    corr3 = CPUCorrelator(template_mem3[corr_slice], det3_fs[corr_slice], corr_mem3[corr_slice])\n",
    "    ifft1 = IFFT(corr_mem1, snr_mem1)\n",
    "    ifft2 = IFFT(corr_mem2, snr_mem2)\n",
    "    ifft3 = IFFT(corr_mem3, snr_mem3)\n",
    "        \n",
    "    max_icv = 0\n",
    "    count = 0\n",
    "    for (hp, ps1, ps2, ps3) in zip(pregenerated_waveforms, pregenerated_sigma1s, pregenerated_sigma2s, pregenerated_sigma3s):\n",
    "\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print (count, 'of', len(mass1s)) # basic tqdm\n",
    "        template_mem1._data[:len(hp)] = hp._data[:]\n",
    "        template_mem2._data[:len(hp)] = hp._data[:]\n",
    "        template_mem3._data[:len(hp)] = hp._data[:]\n",
    "        \n",
    "        template_norm1 = ps1\n",
    "        template_norm2 = ps2\n",
    "        template_norm3 = ps3\n",
    "\n",
    "        norm1 = (4.0 * det1_psd.delta_f) / np.sqrt(template_norm1)\n",
    "        norm2 = (4.0 * det2_psd.delta_f) / np.sqrt(template_norm2)\n",
    "        norm3 = (4.0 * det3_psd.delta_f) / np.sqrt(template_norm3)\n",
    "        \n",
    "        corr1.correlate()\n",
    "        ifft1.execute()\n",
    "        \n",
    "        corr2.correlate()\n",
    "        ifft2.execute()\n",
    "\n",
    "        corr3.correlate()\n",
    "        ifft3.execute()\n",
    "                 \n",
    "        # NOTE [2048:3686] is -1, -0.2 ... But I swapped to 3030:3745\n",
    "        max_det1_filter = abs(snr_mem1._data[3030:3745]).argmax()\n",
    "        det1_max = abs(snr_mem1._data[max_det1_filter+3030]) * norm1 # finding the max snr\n",
    "    \n",
    "        max_det2_filter = abs(snr_mem2._data[3030:3745]).argmax()\n",
    "        det2_max = abs(snr_mem2._data[max_det2_filter+3030]) * norm2\n",
    "  \n",
    "        max_det3_filter = abs(snr_mem3._data[3030:3745]).argmax()\n",
    "        det3_max = abs(snr_mem3._data[max_det3_filter+3030]) * norm3\n",
    "        \n",
    "        max_filter = (det1_max+det2_max+det3_max)\n",
    "        \n",
    "        \n",
    "        if max_filter > max_icv:\n",
    "            max_icv = max_filter\n",
    "            \n",
    "                \n",
    "    \n",
    "    det_filter_final.append((max_icv, filname.split('/')[-1][:-4]))\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25319d-8a37-43e0-a5a3-d0c7f97584cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(det_filter_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72430f-91d4-41df-926a-4f51f2e82be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the Data\n",
    "import csv\n",
    "with open('filterfile.txt',\"w\") as f:\n",
    "    csv.writer(f, delimiter =',').writerows(det_filter_final) # Writing the list to a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9203a04-08cf-4c25-ae5e-f2a10bcee887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "final_dat = pd.read_csv('filterfile.txt',sep=',', header = None)\n",
    "final_data = final_dat.iloc[:,0]\n",
    "print(len(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac83157-d22a-42a5-a992-1ab7d9b65c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(list())\n",
    "dat.to_csv('matchv1.csv')\n",
    "matchv1 = pd.read_csv('matchv1.csv') # Creating a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b71e6-3937-4168-bae9-537fe80b672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = training_labels['id'].values[0:data_size]\n",
    "actual_targets = training_labels['target'].values[0:data_size]\n",
    "print(len(ids),len(actual_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32e7cb-bc2d-4747-b544-c6a62f6d8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_target = np.array(final_data)\n",
    "match_target[:,] = match_target[:,] > 15 # Setting a threshold for binary classification \n",
    "match_target = match_target.astype(int)\n",
    "print(match_target)\n",
    "print(len(match_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fe5fe-ea3a-434e-9b65-50b61f0352c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_target = []\n",
    "mat_tar = list(match_target)\n",
    "actu_tar = list(actual_targets)\n",
    "\n",
    "for i in range(len(mat_tar)):\n",
    "    if mat_tar[i] == actu_tar[i]:\n",
    "        frac_target.append(1)\n",
    "    else:\n",
    "        frac_target.append(0)\n",
    "print(len(frac_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a454ac3-329f-479e-a1c8-672e36c6e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchv1 = pd.DataFrame({'id':ids, 'Max SNRs': final_data, \n",
    "                     'Match Targets': match_target,\n",
    "                     'Actual Targets': actual_targets,\n",
    "                     'Classified Targets': frac_target})\n",
    "matchv1.to_csv('matchv1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9c1d8-82ed-4fd0-b70d-5176a78bb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchv1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faabc1f-7607-4acf-a7cd-76362511f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ones = np.count_nonzero(frac_target)\n",
    "acc_score_match = (no_ones/len(frac_target))*100\n",
    "error_score_match = (100-acc_score_match)\n",
    "print('Classified Correctly: ',acc_score_match, 'Classified Incorrectly: ',error_score_match)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igwn-py39",
   "language": "python",
   "name": "igwn-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
